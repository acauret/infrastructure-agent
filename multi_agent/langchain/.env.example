# Environment configuration for LangChain Multi-Agent System
LOG_LEVEL=INFO

# Azure AI Inference Configuration
AZURE_AI_INFERENCE_ENDPOINT=https://models.inference.ai.azure.com
AZURE_AI_INFERENCE_API_KEY=your_key_here
AZURE_OPENAI_KEY=your_key_here

# Model Configuration for Agents
# Available models: gpt-4, gpt-4o, gpt-35-turbo, mistral-large, mistral-small, llama-3-8b-instruct, etc.
AZURE_AGENT_MODEL=gpt-4
GITHUB_AGENT_MODEL=mistral-small
ORCHESTRATOR_MODEL=Mistral-Large-2411

# Model Parameters (optional)
MODEL_TEMPERATURE=0.1
MODEL_MAX_TOKENS=4000

# Azure MCP Configuration  
AZURE_SUBSCRIPTION_ID=your_subscription_id
AZURE_CLIENT_ID=your_client_id
AZURE_CLIENT_SECRET=your_client_secret
AZURE_TENANT_ID=your_tenant_id

# GitHub MCP Configuration
GITHUB_TOKEN=your_github_token

# Azure MCP Configuration  
AZURE_SUBSCRIPTION_ID=your_subscription_id
AZURE_CLIENT_ID=your_client_id
AZURE_CLIENT_SECRET=your_client_secret
AZURE_TENANT_ID=your_tenant_id

# GitHub MCP Configuration
GITHUB_TOKEN=your_github_token
